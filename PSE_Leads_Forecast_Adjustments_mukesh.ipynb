{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_survival</th>\n",
       "      <th>avg_cumhaz</th>\n",
       "      <th>dtc</th>\n",
       "      <th>date_lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981331</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973561</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964657</td>\n",
       "      <td>0.036067</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.953434</td>\n",
       "      <td>0.047829</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941074</td>\n",
       "      <td>0.060961</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.929387</td>\n",
       "      <td>0.073556</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.915226</td>\n",
       "      <td>0.089054</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.897893</td>\n",
       "      <td>0.108385</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.881872</td>\n",
       "      <td>0.126625</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.866037</td>\n",
       "      <td>0.145013</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_survival  avg_cumhaz  dtc  date_lead\n",
       "0      0.981331    0.018871    0 2017-03-01\n",
       "1      0.973561    0.026843    1 2017-03-01\n",
       "2      0.964657    0.036067    2 2017-03-01\n",
       "3      0.953434    0.047829    3 2017-03-01\n",
       "4      0.941074    0.060961    4 2017-03-01\n",
       "5      0.929387    0.073556    5 2017-03-01\n",
       "6      0.915226    0.089054    6 2017-03-01\n",
       "7      0.897893    0.108385    7 2017-03-01\n",
       "8      0.881872    0.126625    8 2017-03-01\n",
       "9      0.866037    0.145013    9 2017-03-01"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lead and dtc level scores\n",
    "lead_dtc_scores = pd.read_excel(\"C:\\\\Users\\\\skbandha\\\\OneDrive - Lowe's Companies Inc\\\\Projects\\\\PSE Leads\\Mar_May_2017.xlsx\")\n",
    "lead_dtc_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converts</th>\n",
       "      <th>date_lead</th>\n",
       "      <th>date_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   converts  date_lead  date_sold\n",
       "0         1 2017-01-01 2017-01-02\n",
       "1         1 2017-01-01 2017-01-04\n",
       "2         3 2017-01-01 2017-01-05\n",
       "3         6 2017-01-01 2017-01-06\n",
       "4         4 2017-01-01 2017-01-09\n",
       "5         4 2017-01-01 2017-01-10\n",
       "6         3 2017-01-01 2017-01-11\n",
       "7         3 2017-01-01 2017-01-12\n",
       "8         3 2017-01-01 2017-01-13\n",
       "9         1 2017-01-01 2017-01-14"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leads converted\n",
    "lead_actual_converted = pd.read_excel(\"C:\\\\Users\\\\skbandha\\\\OneDrive - Lowe's Companies Inc\\\\Projects\\\\PSE Leads\\Lead_Converted_17_18_PSE.xlsx\")\n",
    "lead_actual_converted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample    lead_gen  date_lead\n",
      "0       792 2018-01-01\n",
      "1      1716 2018-01-02\n",
      "2      1402 2018-01-03\n",
      "3      1344 2018-01-04\n",
      "4      1532 2018-01-05\n",
      "5      1351 2018-01-06\n",
      "6       821 2018-01-07\n",
      "7      1589 2018-01-08\n",
      "8      1545 2018-01-09\n",
      "9      1493 2018-01-10\n",
      "Minimmum Date 2018-01-01 00:00:00\n",
      "Maximum Date 2018-08-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#Number of leads generated\n",
    "leads_generated_2018 = pd.read_excel(\"C:\\\\Users\\\\skbandha\\\\OneDrive - Lowe's Companies Inc\\\\Projects\\\\PSE Leads\\Lead_gen_18.xlsx\")\n",
    "print(\"Sample\", leads_generated_2018.head(10))\n",
    "print(\"Minimmum Date\", min(leads_generated_2018.date_lead))\n",
    "print(\"Maximum Date\", max(leads_generated_2018.date_lead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample    date_lead  lead_gen\n",
      "0 2017-03-01      1993\n",
      "1 2017-03-02      2142\n",
      "2 2017-03-03      2256\n",
      "3 2017-03-04      2605\n",
      "4 2017-03-05      1545\n",
      "5 2017-03-06      2648\n",
      "6 2017-03-07      2346\n",
      "7 2017-03-08      2169\n",
      "8 2017-03-09      2588\n",
      "9 2017-03-10      2230\n",
      "Minimmum Date 2017-03-01 00:00:00\n",
      "Maximum Date 2017-05-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#Number of leads generated - Mar to May 17\n",
    "leads_generated_2017 = pd.read_excel(\"C:\\\\Users\\\\skbandha\\\\OneDrive - Lowe's Companies Inc\\\\Projects\\\\PSE Leads\\Leads_Generated_Mar_May17.xlsx\")\n",
    "print(\"Sample\", leads_generated_2017.head(10))\n",
    "print(\"Minimmum Date\", min(leads_generated_2017.date_lead))\n",
    "print(\"Maximum Date\", max(leads_generated_2017.date_lead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample    dtc  avg_survival  avg_cumhaz\n",
      "0    0      0.984163    0.015988\n",
      "1    1      0.977496    0.022806\n",
      "2    2      0.969845    0.030696\n",
      "3    3      0.960152    0.040793\n",
      "4    4      0.949368    0.052159\n",
      "5    5      0.939184    0.063030\n",
      "6    6      0.926809    0.076418\n",
      "7    7      0.911627    0.093115\n",
      "8    8      0.897419    0.109019\n",
      "9    9      0.883391    0.125000\n"
     ]
    }
   ],
   "source": [
    "#DTC Survival probabilities\n",
    "survival_probs_dtc = pd.read_excel(\"C:\\\\Users\\\\skbandha\\\\OneDrive - Lowe's Companies Inc\\\\Projects\\\\PSE Leads\\DTC_Surv_Probs.xlsx\")\n",
    "#rename columns\n",
    "survival_probs_dtc.rename(columns = {'St':'avg_survival', 'Cum_haz':'avg_cumhaz'}, inplace = True)\n",
    "\n",
    "print(\"Sample\", survival_probs_dtc.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_survival  avg_cumhaz  dtc  date_lead\n",
      "0      0.982498    0.017695    0 2018-02-01\n",
      "1      0.982382    0.017813    0 2018-02-02\n",
      "2      0.981174    0.019039    0 2018-02-03\n",
      "3      0.982565    0.017629    0 2018-02-04\n",
      "4      0.982398    0.017796    0 2018-02-05\n",
      "5      0.982578    0.017615    0 2018-02-06\n",
      "6      0.982812    0.017375    0 2018-02-07\n",
      "7      0.981876    0.018326    0 2018-02-08\n",
      "8      0.982081    0.018119    0 2018-02-09\n",
      "9      0.981244    0.018968    0 2018-02-10\n"
     ]
    }
   ],
   "source": [
    "#Survival Probabilities from Feb to Aug '18\n",
    "probs_feb_aug18 = pd.read_excel(\"C:\\\\Users\\\\skbandha\\\\OneDrive - Lowe's Companies Inc\\\\Projects\\\\PSE Leads\\Feb_aug18.xlsx\")\n",
    "print(probs_feb_aug18.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building for Mar to May 2017 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assigning attributes\n",
    "lead_probs_28day = lead_dtc_scores\n",
    "dtc_surv_probs = survival_probs_dtc\n",
    "leads_number = leads_generated_2017\n",
    "actuals = lead_actual_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency by Date date_lead\n",
      "2017-03-01    50\n",
      "2017-03-02    50\n",
      "2017-03-03    50\n",
      "2017-03-04    50\n",
      "2017-03-05    50\n",
      "2017-03-06    50\n",
      "2017-03-07    50\n",
      "2017-03-08    50\n",
      "2017-03-09    50\n",
      "2017-03-10    50\n",
      "2017-03-11    50\n",
      "2017-03-12    50\n",
      "2017-03-13    50\n",
      "2017-03-14    50\n",
      "2017-03-15    50\n",
      "2017-03-16    50\n",
      "2017-03-17    50\n",
      "2017-03-18    50\n",
      "2017-03-19    50\n",
      "2017-03-20    50\n",
      "2017-03-21    50\n",
      "2017-03-22    50\n",
      "2017-03-23    50\n",
      "2017-03-24    50\n",
      "2017-03-25    50\n",
      "2017-03-26    50\n",
      "2017-03-27    50\n",
      "2017-03-28    50\n",
      "2017-03-29    50\n",
      "2017-03-30    50\n",
      "              ..\n",
      "2017-05-02    50\n",
      "2017-05-03    50\n",
      "2017-05-04    50\n",
      "2017-05-05    50\n",
      "2017-05-06    50\n",
      "2017-05-07    50\n",
      "2017-05-08    50\n",
      "2017-05-09    50\n",
      "2017-05-10    50\n",
      "2017-05-11    50\n",
      "2017-05-12    50\n",
      "2017-05-13    50\n",
      "2017-05-14    50\n",
      "2017-05-15    50\n",
      "2017-05-16    50\n",
      "2017-05-17    50\n",
      "2017-05-18    50\n",
      "2017-05-19    50\n",
      "2017-05-20    50\n",
      "2017-05-21    50\n",
      "2017-05-22    50\n",
      "2017-05-23    50\n",
      "2017-05-24    50\n",
      "2017-05-25    50\n",
      "2017-05-26    50\n",
      "2017-05-27    50\n",
      "2017-05-28    50\n",
      "2017-05-29    50\n",
      "2017-05-30    50\n",
      "2017-05-31    50\n",
      "Length: 92, dtype: int64\n",
      "    avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob\n",
      "0     0.018871      0.981331 2017-03-01    0       NaN       0.018871\n",
      "1     0.026843      0.973561 2017-03-01    1  0.018871       0.007972\n",
      "2     0.036067      0.964657 2017-03-01    2  0.026843       0.009224\n",
      "3     0.047829      0.953434 2017-03-01    3  0.036067       0.011762\n",
      "4     0.060961      0.941074 2017-03-01    4  0.047829       0.013131\n",
      "5     0.073556      0.929387 2017-03-01    5  0.060961       0.012595\n",
      "6     0.089054      0.915226 2017-03-01    6  0.073556       0.015498\n",
      "7     0.108385      0.897893 2017-03-01    7  0.089054       0.019331\n",
      "8     0.126625      0.881872 2017-03-01    8  0.108385       0.018240\n",
      "9     0.145013      0.866037 2017-03-01    9  0.126625       0.018389\n",
      "10    0.164120      0.849918 2017-03-01   10  0.145013       0.019107\n",
      "11    0.183192      0.834156 2017-03-01   11  0.164120       0.019072\n",
      "12    0.200269      0.820326 2017-03-01   12  0.183192       0.017077\n",
      "13    0.219660      0.804931 2017-03-01   13  0.200269       0.019391\n",
      "14    0.240474      0.788750 2017-03-01   14  0.219660       0.020814\n",
      "15    0.259037      0.774620 2017-03-01   15  0.240474       0.018563\n",
      "16    0.277080      0.761161 2017-03-01   16  0.259037       0.018043\n",
      "17    0.295548      0.747657 2017-03-01   17  0.277080       0.018468\n",
      "18    0.313173      0.735016 2017-03-01   18  0.295548       0.017624\n",
      "19    0.328823      0.723988 2017-03-01   19  0.313173       0.015651\n",
      "20    0.346120      0.712011 2017-03-01   20  0.328823       0.017296\n",
      "21    0.363887      0.699931 2017-03-01   21  0.346120       0.017767\n",
      "22    0.379583      0.689455 2017-03-01   22  0.363887       0.015696\n",
      "23    0.395317      0.679131 2017-03-01   23  0.379583       0.015734\n",
      "24    0.411454      0.668713 2017-03-01   24  0.395317       0.016137\n",
      "25    0.426855      0.658937 2017-03-01   25  0.411454       0.015402\n",
      "26    0.440708      0.650287 2017-03-01   26  0.426855       0.013853\n",
      "27    0.455471      0.641214 2017-03-01   27  0.440708       0.014762\n",
      "28    0.470750      0.631958 2017-03-01   28  0.455471       0.015279\n",
      "29    0.018674      0.981524 2017-03-02    0       NaN       0.018674\n",
      "30    0.026559      0.973838 2017-03-02    1  0.018674       0.007885\n",
      "31    0.035681      0.965029 2017-03-02    2  0.026559       0.009122\n",
      "32    0.047308      0.953930 2017-03-02    3  0.035681       0.011627\n",
      "33    0.060307      0.941687 2017-03-02    4  0.047308       0.012999\n",
      "34    0.072768      0.930117 2017-03-02    5  0.060307       0.012460\n",
      "35    0.088100      0.916096 2017-03-02    6  0.072768       0.015333\n",
      "36    0.107189      0.898963 2017-03-02    7  0.088100       0.019089\n",
      "37    0.125267      0.883063 2017-03-02    8  0.107189       0.018078\n",
      "38    0.143442      0.867391 2017-03-02    9  0.125267       0.018175\n",
      "39    0.162360      0.851405 2017-03-02   10  0.143442       0.018918\n",
      "40    0.181238      0.835776 2017-03-02   11  0.162360       0.018878\n",
      "41    0.198155      0.822047 2017-03-02   12  0.181238       0.016916\n",
      "42    0.217352      0.806773 2017-03-02   13  0.198155       0.019198\n",
      "43    0.237955      0.790718 2017-03-02   14  0.217352       0.020603\n",
      "44    0.256316      0.776706 2017-03-02   15  0.237955       0.018361\n",
      "45    0.274178      0.763345 2017-03-02   16  0.256316       0.017863\n",
      "46    0.292465      0.749934 2017-03-02   17  0.274178       0.018287\n",
      "47    0.309906      0.737386 2017-03-02   18  0.292465       0.017441\n",
      "48    0.325397      0.726434 2017-03-02   19  0.309906       0.015492\n",
      "49    0.342528      0.714531 2017-03-02   20  0.325397       0.017131\n",
      "50    0.360117      0.702528 2017-03-02   21  0.342528       0.017589\n",
      "51    0.375695      0.692088 2017-03-02   22  0.360117       0.015578\n",
      "52    0.391301      0.681806 2017-03-02   23  0.375695       0.015606\n",
      "53    0.407290      0.671439 2017-03-02   24  0.391301       0.015990\n",
      "54    0.422528      0.661728 2017-03-02   25  0.407290       0.015238\n",
      "55    0.436249      0.653122 2017-03-02   26  0.422528       0.013721\n",
      "56    0.450893      0.644079 2017-03-02   27  0.436249       0.014644\n",
      "57    0.465967      0.634910 2017-03-02   28  0.450893       0.015073\n",
      "58    0.018696      0.981503 2017-03-03    0       NaN       0.018696\n",
      "59    0.026593      0.973806 2017-03-03    1  0.018696       0.007897\n"
     ]
    }
   ],
   "source": [
    "#Creating one source for all probabilities\n",
    "dist_lead_dates = pd.DataFrame(lead_probs_28day['date_lead'].unique()).reset_index()\n",
    "#print(list(dist_lead_dates.columns.values))\n",
    "dist_lead_dates.rename(columns = {0:'date_lead'}, inplace = True)\n",
    "\n",
    "cols_to_drop = dist_lead_dates['index']\n",
    "dist_lead_dates = dist_lead_dates[['date_lead']]\n",
    "#print(\"Sample\",dist_lead_dates.head(10))\n",
    "\n",
    "#Cartesian product of dtc and lead dates\n",
    "dist_lead_dates['key'] = 0\n",
    "dtc_surv_probs['key'] = 0\n",
    "\n",
    "probs_29_49 = dist_lead_dates.merge(dtc_surv_probs, how = 'left', on = 'key')\n",
    "#print(probs_29_49.groupby(['date_lead']).size())\n",
    "\n",
    "#Calculating marginal probabilities\n",
    "probs_29_49.sort_values(by = ['date_lead', 'dtc'])\n",
    "probs_29_49['lag'] = probs_29_49.groupby(['date_lead'])['avg_cumhaz'].shift(1)\n",
    "#print(probs_29_49.head(20))\n",
    "\n",
    "probs_29_49['marginal_prob'] = np.where(probs_29_49['dtc'] == 0, probs_29_49['avg_cumhaz'], probs_29_49['avg_cumhaz'] - probs_29_49['lag'])\n",
    "#print(probs_29_49.head(60))\n",
    "\n",
    "lead_probs_28day.sort_values(by = ['date_lead', 'dtc'])\n",
    "lead_probs_28day['lag'] = lead_probs_28day.groupby(['date_lead'])['avg_cumhaz'].shift(1)\n",
    "#print(probs_29_49.head(20))\n",
    "\n",
    "lead_probs_28day['marginal_prob'] = np.where(lead_probs_28day['dtc'] == 0, lead_probs_28day['avg_cumhaz'], lead_probs_28day['avg_cumhaz'] - lead_probs_28day['lag'])\n",
    "#print(lead_probs_28day.head(60))\n",
    "\n",
    "#Restricting the probabilities to only 29 to 49 probabilities only\n",
    "probs_29_49 = probs_29_49[(probs_29_49['dtc'] <= 49) & (probs_29_49['dtc'] >= 29)]\n",
    "#print(probs_29_49.groupby(['date_lead']).size())\n",
    "\n",
    "#Appending the 28 day forecast with 29 forecast\n",
    "final_probs = lead_probs_28day.append(probs_29_49, ignore_index = True)\n",
    "final_probs = final_probs.drop(['key'], axis = 1)\n",
    "final_probs.sort_values(by = ['date_lead', 'dtc'])\n",
    "print(\"Frequency by Date\",final_probs.groupby(['date_lead']).size())\n",
    "print(final_probs.head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_cumhaz</th>\n",
       "      <th>avg_survival</th>\n",
       "      <th>date_lead</th>\n",
       "      <th>dtc</th>\n",
       "      <th>lag</th>\n",
       "      <th>marginal_prob</th>\n",
       "      <th>lead_gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.981331</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026843</td>\n",
       "      <td>0.973561</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036067</td>\n",
       "      <td>0.964657</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047829</td>\n",
       "      <td>0.953434</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.036067</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060961</td>\n",
       "      <td>0.941074</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.047829</td>\n",
       "      <td>0.013131</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.073556</td>\n",
       "      <td>0.929387</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.060961</td>\n",
       "      <td>0.012595</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.089054</td>\n",
       "      <td>0.915226</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.073556</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.108385</td>\n",
       "      <td>0.897893</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.089054</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.126625</td>\n",
       "      <td>0.881872</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.108385</td>\n",
       "      <td>0.018240</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.145013</td>\n",
       "      <td>0.866037</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>9</td>\n",
       "      <td>0.126625</td>\n",
       "      <td>0.018389</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob  lead_gen\n",
       "0    0.018871      0.981331 2017-03-01    0       NaN       0.018871      1993\n",
       "1    0.026843      0.973561 2017-03-01    1  0.018871       0.007972      1993\n",
       "2    0.036067      0.964657 2017-03-01    2  0.026843       0.009224      1993\n",
       "3    0.047829      0.953434 2017-03-01    3  0.036067       0.011762      1993\n",
       "4    0.060961      0.941074 2017-03-01    4  0.047829       0.013131      1993\n",
       "5    0.073556      0.929387 2017-03-01    5  0.060961       0.012595      1993\n",
       "6    0.089054      0.915226 2017-03-01    6  0.073556       0.015498      1993\n",
       "7    0.108385      0.897893 2017-03-01    7  0.089054       0.019331      1993\n",
       "8    0.126625      0.881872 2017-03-01    8  0.108385       0.018240      1993\n",
       "9    0.145013      0.866037 2017-03-01    9  0.126625       0.018389      1993"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging with number of leads\n",
    "final_probs = final_probs.merge(leads_number, how = 'left', on = 'date_lead')\n",
    "final_probs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_cumhaz              float64\n",
      "avg_survival            float64\n",
      "date_lead        datetime64[ns]\n",
      "dtc                       int64\n",
      "lag                     float64\n",
      "marginal_prob           float64\n",
      "lead_gen                  int64\n",
      "date_sold        datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "converts              int64\n",
      "date_lead    datetime64[ns]\n",
      "date_sold    datetime64[ns]\n",
      "dtype: object\n",
      "   converts  date_lead  date_sold\n",
      "0         1 2017-01-01 2017-01-02\n",
      "1         1 2017-01-01 2017-01-04\n",
      "2         3 2017-01-01 2017-01-05\n",
      "3         6 2017-01-01 2017-01-06\n",
      "4         4 2017-01-01 2017-01-09\n",
      "5         4 2017-01-01 2017-01-10\n",
      "6         3 2017-01-01 2017-01-11\n",
      "7         3 2017-01-01 2017-01-12\n",
      "8         3 2017-01-01 2017-01-13\n",
      "9         1 2017-01-01 2017-01-14\n"
     ]
    }
   ],
   "source": [
    "#Matching with actuals\n",
    "\n",
    "#Create date_sold\n",
    "final_probs['date_sold'] = final_probs['date_lead']\n",
    "final_probs['date_sold'] += pd.to_timedelta(final_probs['dtc'], unit = 'D')\n",
    "final_probs.head(10)\n",
    "\n",
    "print(final_probs.dtypes)\n",
    "print(\"\")\n",
    "print(actuals.dtypes)\n",
    "print(actuals.head(10))\n",
    "\n",
    "final_probs = final_probs.merge(actuals, how = 'left', on = ['date_lead', 'date_sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob  \\\n",
      "0    0.018871      0.981331 2017-03-01    0       NaN       0.018871   \n",
      "1    0.026843      0.973561 2017-03-01    1  0.018871       0.007972   \n",
      "2    0.036067      0.964657 2017-03-01    2  0.026843       0.009224   \n",
      "3    0.047829      0.953434 2017-03-01    3  0.036067       0.011762   \n",
      "4    0.060961      0.941074 2017-03-01    4  0.047829       0.013131   \n",
      "5    0.073556      0.929387 2017-03-01    5  0.060961       0.012595   \n",
      "6    0.089054      0.915226 2017-03-01    6  0.073556       0.015498   \n",
      "7    0.108385      0.897893 2017-03-01    7  0.089054       0.019331   \n",
      "8    0.126625      0.881872 2017-03-01    8  0.108385       0.018240   \n",
      "9    0.145013      0.866037 2017-03-01    9  0.126625       0.018389   \n",
      "\n",
      "   lead_gen  date_sold  converts  predicted_converts  \n",
      "0      1993 2017-03-01      24.0           36.907294  \n",
      "1      1993 2017-03-02      20.0           15.468968  \n",
      "2      1993 2017-03-03      31.0           17.733714  \n",
      "3      1993 2017-03-04      12.0           22.350196  \n",
      "4      1993 2017-03-05       1.0           24.628869  \n",
      "5      1993 2017-03-06      26.0           23.329656  \n",
      "6      1993 2017-03-07      22.0           28.269347  \n",
      "7      1993 2017-03-08      13.0           34.592314  \n",
      "8      1993 2017-03-09      32.0           32.058020  \n",
      "9      1993 2017-03-10      44.0           31.738908  \n"
     ]
    }
   ],
   "source": [
    "#Predicted probability\n",
    "final_probs['predicted_converts'] = final_probs['avg_survival'] * final_probs['marginal_prob'] * final_probs['lead_gen']\n",
    "print(final_probs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob  \\\n",
      "0    0.018871      0.981331 2017-03-01    0       NaN       0.018871   \n",
      "1    0.026843      0.973561 2017-03-01    1  0.018871       0.007972   \n",
      "2    0.036067      0.964657 2017-03-01    2  0.026843       0.009224   \n",
      "3    0.047829      0.953434 2017-03-01    3  0.036067       0.011762   \n",
      "4    0.060961      0.941074 2017-03-01    4  0.047829       0.013131   \n",
      "5    0.073556      0.929387 2017-03-01    5  0.060961       0.012595   \n",
      "6    0.089054      0.915226 2017-03-01    6  0.073556       0.015498   \n",
      "7    0.108385      0.897893 2017-03-01    7  0.089054       0.019331   \n",
      "8    0.126625      0.881872 2017-03-01    8  0.108385       0.018240   \n",
      "9    0.145013      0.866037 2017-03-01    9  0.126625       0.018389   \n",
      "\n",
      "   lead_gen  date_sold  converts  predicted_converts dtc_weekday  \n",
      "0      1993 2017-03-01      24.0           36.907294   Wednesday  \n",
      "1      1993 2017-03-02      20.0           15.468968    Thursday  \n",
      "2      1993 2017-03-03      31.0           17.733714      Friday  \n",
      "3      1993 2017-03-04      12.0           22.350196    Saturday  \n",
      "4      1993 2017-03-05       1.0           24.628869      Sunday  \n",
      "5      1993 2017-03-06      26.0           23.329656      Monday  \n",
      "6      1993 2017-03-07      22.0           28.269347     Tuesday  \n",
      "7      1993 2017-03-08      13.0           34.592314   Wednesday  \n",
      "8      1993 2017-03-09      32.0           32.058020    Thursday  \n",
      "9      1993 2017-03-10      44.0           31.738908      Friday  \n"
     ]
    }
   ],
   "source": [
    "#Creating weekdays\n",
    "final_probs['dtc_weekday'] = final_probs['date_sold'].dt.weekday_name\n",
    "print(final_probs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob  \\\n",
      "0    0.018871      0.981331 2017-03-01    0       NaN       0.018871   \n",
      "1    0.026843      0.973561 2017-03-01    1  0.018871       0.007972   \n",
      "2    0.036067      0.964657 2017-03-01    2  0.026843       0.009224   \n",
      "3    0.047829      0.953434 2017-03-01    3  0.036067       0.011762   \n",
      "4    0.060961      0.941074 2017-03-01    4  0.047829       0.013131   \n",
      "5    0.073556      0.929387 2017-03-01    5  0.060961       0.012595   \n",
      "6    0.089054      0.915226 2017-03-01    6  0.073556       0.015498   \n",
      "7    0.108385      0.897893 2017-03-01    7  0.089054       0.019331   \n",
      "8    0.126625      0.881872 2017-03-01    8  0.108385       0.018240   \n",
      "9    0.145013      0.866037 2017-03-01    9  0.126625       0.018389   \n",
      "\n",
      "   lead_gen  date_sold  converts  predicted_converts dtc_weekday     error  \n",
      "0      1993 2017-03-01      24.0           36.907294   Wednesday -0.349722  \n",
      "1      1993 2017-03-02      20.0           15.468968    Thursday  0.292911  \n",
      "2      1993 2017-03-03      31.0           17.733714      Friday  0.748083  \n",
      "3      1993 2017-03-04      12.0           22.350196    Saturday -0.463092  \n",
      "4      1993 2017-03-05       1.0           24.628869      Sunday -0.959397  \n",
      "5      1993 2017-03-06      26.0           23.329656      Monday  0.114461  \n",
      "6      1993 2017-03-07      22.0           28.269347     Tuesday -0.221772  \n",
      "7      1993 2017-03-08      13.0           34.592314   Wednesday -0.624194  \n",
      "8      1993 2017-03-09      32.0           32.058020    Thursday -0.001810  \n",
      "9      1993 2017-03-10      44.0           31.738908      Friday  0.386311  \n"
     ]
    }
   ],
   "source": [
    "#Creating dependent variable\n",
    "final_probs['error'] = (final_probs['converts'] - final_probs['predicted_converts']) / final_probs['predicted_converts']\n",
    "print(final_probs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model - correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>error</td>      <th>  R-squared:         </th> <td>   0.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1206.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 29 Sep 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:44:10</td>     <th>  Log-Likelihood:    </th> <td>  241.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4193</td>      <th>  AIC:               </th> <td>  -466.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4185</td>      <th>  BIC:               </th> <td>  -416.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>    0.3301</td> <td>    0.011</td> <td>   30.501</td> <td> 0.000</td> <td>    0.309</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dtc_weekday[T.Monday]</th>    <td>   -0.3706</td> <td>    0.013</td> <td>  -29.187</td> <td> 0.000</td> <td>   -0.396</td> <td>   -0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dtc_weekday[T.Saturday]</th>  <td>   -0.6210</td> <td>    0.013</td> <td>  -48.285</td> <td> 0.000</td> <td>   -0.646</td> <td>   -0.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dtc_weekday[T.Sunday]</th>    <td>   -0.9312</td> <td>    0.015</td> <td>  -61.390</td> <td> 0.000</td> <td>   -0.961</td> <td>   -0.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dtc_weekday[T.Thursday]</th>  <td>   -0.3215</td> <td>    0.013</td> <td>  -25.322</td> <td> 0.000</td> <td>   -0.346</td> <td>   -0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dtc_weekday[T.Tuesday]</th>   <td>   -0.4055</td> <td>    0.013</td> <td>  -31.958</td> <td> 0.000</td> <td>   -0.430</td> <td>   -0.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dtc_weekday[T.Wednesday]</th> <td>   -0.4981</td> <td>    0.013</td> <td>  -39.102</td> <td> 0.000</td> <td>   -0.523</td> <td>   -0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dtc</th>                      <td>   -0.0167</td> <td>    0.000</td> <td>  -66.709</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>445.512</td> <th>  Durbin-Watson:     </th> <td>   1.719</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 986.142</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.651</td>  <th>  Prob(JB):          </th> <td>7.28e-215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.987</td>  <th>  Cond. No.          </th> <td>    199.</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  error   R-squared:                       0.669\n",
       "Model:                            OLS   Adj. R-squared:                  0.668\n",
       "Method:                 Least Squares   F-statistic:                     1206.\n",
       "Date:                Sat, 29 Sep 2018   Prob (F-statistic):               0.00\n",
       "Time:                        22:44:10   Log-Likelihood:                 241.41\n",
       "No. Observations:                4193   AIC:                            -466.8\n",
       "Df Residuals:                    4185   BIC:                            -416.1\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                    0.3301      0.011     30.501      0.000       0.309       0.351\n",
       "dtc_weekday[T.Monday]       -0.3706      0.013    -29.187      0.000      -0.396      -0.346\n",
       "dtc_weekday[T.Saturday]     -0.6210      0.013    -48.285      0.000      -0.646      -0.596\n",
       "dtc_weekday[T.Sunday]       -0.9312      0.015    -61.390      0.000      -0.961      -0.901\n",
       "dtc_weekday[T.Thursday]     -0.3215      0.013    -25.322      0.000      -0.346      -0.297\n",
       "dtc_weekday[T.Tuesday]      -0.4055      0.013    -31.958      0.000      -0.430      -0.381\n",
       "dtc_weekday[T.Wednesday]    -0.4981      0.013    -39.102      0.000      -0.523      -0.473\n",
       "dtc                         -0.0167      0.000    -66.709      0.000      -0.017      -0.016\n",
       "==============================================================================\n",
       "Omnibus:                      445.512   Durbin-Watson:                   1.719\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              986.142\n",
       "Skew:                           0.651   Prob(JB):                    7.28e-215\n",
       "Kurtosis:                       4.987   Cond. No.                         199.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "reg = smf.ols(formula = \"error~dtc_weekday + dtc\", data = final_probs).fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dtc  new_pred_converts  converts    errors\n",
      "0     0        3486.463821    3479.0  0.002145\n",
      "1     1        1387.957833    1486.0  0.065977\n",
      "2     2        1574.193156    1699.0  0.073459\n",
      "3     3        1969.701375    2043.0  0.035878\n",
      "4     4        2117.260038    2185.0  0.031002\n",
      "5     5        1872.904883    2119.0  0.116137\n",
      "6     6        2313.897238    2589.0  0.106258\n",
      "7     7        2884.660934    2948.0  0.021485\n",
      "8     8        2520.777480    2817.0  0.105155\n",
      "9     9        2457.307770    2671.0  0.080005\n",
      "10   10        2484.768444    2687.0  0.075263\n",
      "11   11        2354.207715    2506.0  0.060572\n",
      "12   12        1916.400920    2144.0  0.106156\n",
      "13   13        2179.419898    2347.0  0.071402\n",
      "14   14        2350.668974    2411.0  0.025023\n",
      "15   15        1908.032549    1990.0  0.041190\n",
      "16   16        1795.789457    1885.0  0.047327\n",
      "17   17        1776.897366    1726.0  0.029489\n",
      "18   18        1593.305912    1677.0  0.049907\n",
      "19   19        1265.086981    1331.0  0.049521\n",
      "20   20        1415.020554    1426.0  0.007699\n",
      "21   21        1468.855089    1390.0  0.056730\n",
      "22   22        1169.887322    1177.0  0.006043\n",
      "23   23        1127.777153    1067.0  0.056961\n",
      "24   24        1117.058634    1049.0  0.064880\n",
      "25   25         994.113340     982.0  0.012335\n",
      "26   26         774.832794     812.0  0.045772\n",
      "27   27         841.297540     831.0  0.012392\n",
      "28   28         889.292787     808.0  0.100610\n",
      "29   29         667.035090     698.0  0.044362\n",
      "30   30         616.538621     616.0  0.000874\n",
      "31   31         579.829442     604.0  0.040017\n",
      "32   32         538.738641     546.0  0.013299\n",
      "33   33         398.936553     452.0  0.117397\n",
      "34   34         446.297954     466.0  0.042279\n",
      "35   35         480.216456     458.0  0.048508\n",
      "36   36         353.133943     407.0  0.132349\n",
      "37   37         340.469621     388.0  0.122501\n",
      "38   38         315.514831     361.0  0.125998\n",
      "39   39         273.498050     327.0  0.163615\n",
      "40   40         192.491663     304.0  0.366804\n",
      "41   41         217.892260     329.0  0.337713\n",
      "42   42         229.892364     261.0  0.119186\n",
      "43   43         151.905221     271.0  0.439464\n",
      "44   44         146.606305     240.0  0.389140\n",
      "45   45         123.728446     219.0  0.435030\n",
      "46   46          96.527297     211.0  0.542525\n",
      "47   47          39.292438     174.0  0.774181\n",
      "48   48          36.251408     188.0  0.807173\n",
      "49   49          64.814289     173.0  0.625351\n"
     ]
    }
   ],
   "source": [
    "final_scores = final_probs\n",
    "final_scores['weekday_coeff'] = np.where(final_scores['dtc_weekday'] == 'Monday', -0.3706,\n",
    "                                        np.where(final_scores['dtc_weekday'] == 'Tuesday', -0.4055,\n",
    "                                                np.where(final_scores['dtc_weekday'] == 'Wednesday', -0.4981,\n",
    "                                                         np.where(final_scores['dtc_weekday'] == 'Thursday', -0.3215,\n",
    "                                                                  np.where(final_scores['dtc_weekday'] == 'Saturday', -0.6210,\n",
    "                                                                           np.where(final_scores['dtc_weekday'] == 'Sunday', -0.9312,0\n",
    "                                                                                   ))))))\n",
    "\n",
    "final_scores['pred_errors'] = 0.2998 + final_scores['weekday_coeff'] + (-0.0167 * final_scores['dtc'])\n",
    "final_scores['new_pred_converts'] = (1+final_scores['pred_errors']) * final_probs['predicted_converts']\n",
    "\n",
    "predicts = pd.DataFrame(final_scores.groupby(final_scores['dtc'])['new_pred_converts'].sum()).reset_index()\n",
    "actuals = pd.DataFrame(final_scores.groupby(final_scores['dtc'])['converts'].sum()).reset_index()\n",
    "final = predicts.merge(actuals, how = 'left', on = 'dtc')\n",
    "final['errors'] = abs(final['new_pred_converts'] - final['converts'])/final['converts']\n",
    "print(final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating for Feb to Aug Leads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assigning attributes\n",
    "lead_probs_28day = probs_feb_aug18\n",
    "dtc_surv_probs = survival_probs_dtc\n",
    "leads_number = leads_generated_2018\n",
    "actuals = lead_actual_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      avg_survival  avg_cumhaz  dtc  date_lead       lag  marginal_prob\n",
      "0         0.982498    0.017695    0 2018-02-01       NaN       0.017695\n",
      "212       0.975056    0.025331    1 2018-02-01  0.017695       0.007635\n",
      "424       0.966577    0.034114    2 2018-02-01  0.025331       0.008783\n",
      "636       0.955719    0.045488    3 2018-02-01  0.034114       0.011375\n",
      "848       0.943469    0.058490    4 2018-02-01  0.045488       0.013002\n",
      "1060      0.932021    0.070819    5 2018-02-01  0.058490       0.012329\n",
      "1272      0.918038    0.086110    6 2018-02-01  0.070819       0.015291\n",
      "1484      0.901003    0.105091    7 2018-02-01  0.086110       0.018981\n",
      "1696      0.884848    0.123446    8 2018-02-01  0.105091       0.018355\n",
      "1908      0.868956    0.141874    9 2018-02-01  0.123446       0.018428\n",
      "2120      0.852652    0.161166   10 2018-02-01  0.141874       0.019292\n",
      "2332      0.836468    0.180714   11 2018-02-01  0.161166       0.019548\n",
      "2544      0.822299    0.198191   12 2018-02-01  0.180714       0.017478\n",
      "2756      0.806607    0.217960   13 2018-02-01  0.198191       0.019769\n",
      "2968      0.790037    0.239252   14 2018-02-01  0.217960       0.021292\n",
      "3180      0.775354    0.258527   15 2018-02-01  0.239252       0.019275\n",
      "3392      0.761341    0.277316   16 2018-02-01  0.258527       0.018789\n",
      "3604      0.747488    0.296280   17 2018-02-01  0.277316       0.018963\n",
      "3816      0.734409    0.314557   18 2018-02-01  0.296280       0.018277\n",
      "4028      0.723116    0.330622   19 2018-02-01  0.314557       0.016066\n",
      "4240      0.710584    0.348758   20 2018-02-01  0.330622       0.018136\n",
      "4452      0.698054    0.367233   21 2018-02-01  0.348758       0.018475\n",
      "4664      0.686965    0.383869   22 2018-02-01  0.367233       0.016636\n",
      "4876      0.676159    0.400386   23 2018-02-01  0.383869       0.016516\n",
      "5088      0.665322    0.417232   24 2018-02-01  0.400386       0.016846\n",
      "5300      0.655053    0.433493   25 2018-02-01  0.417232       0.016261\n",
      "5512      0.646125    0.447891   26 2018-02-01  0.433493       0.014398\n",
      "5724      0.636905    0.463006   27 2018-02-01  0.447891       0.015116\n",
      "5936      0.627449    0.478763   28 2018-02-01  0.463006       0.015757\n",
      "1         0.982382    0.017813    0 2018-02-02       NaN       0.017813\n",
      "213       0.974950    0.025439    1 2018-02-02  0.017813       0.007626\n",
      "425       0.966482    0.034212    2 2018-02-02  0.025439       0.008773\n",
      "637       0.955657    0.045554    3 2018-02-02  0.034212       0.011342\n",
      "849       0.943466    0.058496    4 2018-02-02  0.045554       0.012942\n",
      "1061      0.932053    0.070790    5 2018-02-02  0.058496       0.012294\n",
      "1273      0.918120    0.086029    6 2018-02-02  0.070790       0.015240\n",
      "1485      0.901181    0.104908    7 2018-02-02  0.086029       0.018878\n",
      "1697      0.885109    0.123174    8 2018-02-02  0.104908       0.018266\n",
      "1909      0.869301    0.141509    9 2018-02-02  0.123174       0.018335\n",
      "2121      0.853075    0.160714   10 2018-02-02  0.141509       0.019205\n",
      "Frequency by Date date_lead\n",
      "2018-02-01    50\n",
      "2018-02-02    50\n",
      "2018-02-03    50\n",
      "2018-02-04    50\n",
      "2018-02-05    50\n",
      "2018-02-06    50\n",
      "2018-02-07    50\n",
      "2018-02-08    50\n",
      "2018-02-09    50\n",
      "2018-02-10    50\n",
      "2018-02-11    50\n",
      "2018-02-12    50\n",
      "2018-02-13    50\n",
      "2018-02-14    50\n",
      "2018-02-15    50\n",
      "2018-02-16    50\n",
      "2018-02-17    50\n",
      "2018-02-18    50\n",
      "2018-02-19    50\n",
      "2018-02-20    50\n",
      "2018-02-21    50\n",
      "2018-02-22    50\n",
      "2018-02-23    50\n",
      "2018-02-24    50\n",
      "2018-02-25    50\n",
      "2018-02-26    50\n",
      "2018-02-27    50\n",
      "2018-02-28    50\n",
      "2018-03-01    50\n",
      "2018-03-02    50\n",
      "              ..\n",
      "2018-08-02    50\n",
      "2018-08-03    50\n",
      "2018-08-04    50\n",
      "2018-08-05    50\n",
      "2018-08-06    50\n",
      "2018-08-07    50\n",
      "2018-08-08    50\n",
      "2018-08-09    50\n",
      "2018-08-10    50\n",
      "2018-08-11    50\n",
      "2018-08-12    50\n",
      "2018-08-13    50\n",
      "2018-08-14    50\n",
      "2018-08-15    50\n",
      "2018-08-16    50\n",
      "2018-08-17    50\n",
      "2018-08-18    50\n",
      "2018-08-19    50\n",
      "2018-08-20    50\n",
      "2018-08-21    50\n",
      "2018-08-22    50\n",
      "2018-08-23    50\n",
      "2018-08-24    50\n",
      "2018-08-25    50\n",
      "2018-08-26    50\n",
      "2018-08-27    50\n",
      "2018-08-28    50\n",
      "2018-08-29    50\n",
      "2018-08-30    50\n",
      "2018-08-31    50\n",
      "Length: 212, dtype: int64\n",
      "    avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob\n",
      "0     0.017695      0.982498 2018-02-01    0       NaN       0.017695\n",
      "1     0.025331      0.975056 2018-02-01    1  0.017695       0.007635\n",
      "2     0.034114      0.966577 2018-02-01    2  0.025331       0.008783\n",
      "3     0.045488      0.955719 2018-02-01    3  0.034114       0.011375\n",
      "4     0.058490      0.943469 2018-02-01    4  0.045488       0.013002\n",
      "5     0.070819      0.932021 2018-02-01    5  0.058490       0.012329\n",
      "6     0.086110      0.918038 2018-02-01    6  0.070819       0.015291\n",
      "7     0.105091      0.901003 2018-02-01    7  0.086110       0.018981\n",
      "8     0.123446      0.884848 2018-02-01    8  0.105091       0.018355\n",
      "9     0.141874      0.868956 2018-02-01    9  0.123446       0.018428\n",
      "10    0.161166      0.852652 2018-02-01   10  0.141874       0.019292\n",
      "11    0.180714      0.836468 2018-02-01   11  0.161166       0.019548\n",
      "12    0.198191      0.822299 2018-02-01   12  0.180714       0.017478\n",
      "13    0.217960      0.806607 2018-02-01   13  0.198191       0.019769\n",
      "14    0.239252      0.790037 2018-02-01   14  0.217960       0.021292\n",
      "15    0.258527      0.775354 2018-02-01   15  0.239252       0.019275\n",
      "16    0.277316      0.761341 2018-02-01   16  0.258527       0.018789\n",
      "17    0.296280      0.747488 2018-02-01   17  0.277316       0.018963\n",
      "18    0.314557      0.734409 2018-02-01   18  0.296280       0.018277\n",
      "19    0.330622      0.723116 2018-02-01   19  0.314557       0.016066\n",
      "20    0.348758      0.710584 2018-02-01   20  0.330622       0.018136\n",
      "21    0.367233      0.698054 2018-02-01   21  0.348758       0.018475\n",
      "22    0.383869      0.686965 2018-02-01   22  0.367233       0.016636\n",
      "23    0.400386      0.676159 2018-02-01   23  0.383869       0.016516\n",
      "24    0.417232      0.665322 2018-02-01   24  0.400386       0.016846\n",
      "25    0.433493      0.655053 2018-02-01   25  0.417232       0.016261\n",
      "26    0.447891      0.646125 2018-02-01   26  0.433493       0.014398\n",
      "27    0.463006      0.636905 2018-02-01   27  0.447891       0.015116\n",
      "28    0.478763      0.627449 2018-02-01   28  0.463006       0.015757\n",
      "29    0.017813      0.982382 2018-02-02    0       NaN       0.017813\n",
      "30    0.025439      0.974950 2018-02-02    1  0.017813       0.007626\n",
      "31    0.034212      0.966482 2018-02-02    2  0.025439       0.008773\n",
      "32    0.045554      0.955657 2018-02-02    3  0.034212       0.011342\n",
      "33    0.058496      0.943466 2018-02-02    4  0.045554       0.012942\n",
      "34    0.070790      0.932053 2018-02-02    5  0.058496       0.012294\n",
      "35    0.086029      0.918120 2018-02-02    6  0.070790       0.015240\n",
      "36    0.104908      0.901181 2018-02-02    7  0.086029       0.018878\n",
      "37    0.123174      0.885109 2018-02-02    8  0.104908       0.018266\n",
      "38    0.141509      0.869301 2018-02-02    9  0.123174       0.018335\n",
      "39    0.160714      0.853075 2018-02-02   10  0.141509       0.019205\n",
      "40    0.180153      0.836986 2018-02-02   11  0.160714       0.019439\n",
      "41    0.197548      0.822887 2018-02-02   12  0.180153       0.017395\n",
      "42    0.217239      0.807259 2018-02-02   13  0.197548       0.019691\n",
      "43    0.238394      0.790800 2018-02-02   14  0.217239       0.021155\n",
      "44    0.257506      0.776245 2018-02-02   15  0.238394       0.019112\n",
      "45    0.276175      0.762323 2018-02-02   16  0.257506       0.018669\n",
      "46    0.295032      0.748549 2018-02-02   17  0.276175       0.018857\n",
      "47    0.313207      0.735543 2018-02-02   18  0.295032       0.018175\n",
      "48    0.329182      0.724313 2018-02-02   19  0.313207       0.015975\n",
      "49    0.347211      0.711854 2018-02-02   20  0.329182       0.018029\n",
      "50    0.365548      0.699418 2018-02-02   21  0.347211       0.018337\n",
      "51    0.382071      0.688401 2018-02-02   22  0.365548       0.016523\n",
      "52    0.398472      0.677668 2018-02-02   23  0.382071       0.016401\n",
      "53    0.415185      0.666915 2018-02-02   24  0.398472       0.016713\n",
      "54    0.431318      0.656723 2018-02-02   25  0.415185       0.016133\n",
      "55    0.445634      0.647842 2018-02-02   26  0.431318       0.014316\n",
      "56    0.460691      0.638651 2018-02-02   27  0.445634       0.015057\n",
      "57    0.476339      0.629256 2018-02-02   28  0.460691       0.015648\n",
      "58    0.019039      0.981174 2018-02-03    0       NaN       0.019039\n",
      "59    0.027074      0.973349 2018-02-03    1  0.019039       0.008035\n"
     ]
    }
   ],
   "source": [
    "#Creating one source for all probabilities\n",
    "dist_lead_dates = pd.DataFrame(lead_probs_28day['date_lead'].unique()).reset_index()\n",
    "#print(list(dist_lead_dates.columns.values))\n",
    "dist_lead_dates.rename(columns = {0:'date_lead'}, inplace = True)\n",
    "\n",
    "cols_to_drop = dist_lead_dates['index']\n",
    "dist_lead_dates = dist_lead_dates[['date_lead']]\n",
    "#print(\"Sample\",dist_lead_dates.head(10))\n",
    "\n",
    "#Cartesian product of dtc and lead dates\n",
    "dist_lead_dates['key'] = 0\n",
    "dtc_surv_probs['key'] = 0\n",
    "\n",
    "probs_29_49 = dist_lead_dates.merge(dtc_surv_probs, how = 'left', on = 'key')\n",
    "#print(probs_29_49.groupby(['date_lead']).size())\n",
    "\n",
    "#Calculating marginal probabilities\n",
    "probs_29_49 = probs_29_49.sort_values(by = ['date_lead', 'dtc'])\n",
    "probs_29_49['lag'] = probs_29_49.groupby(['date_lead'])['avg_cumhaz'].shift(1)\n",
    "#print(probs_29_49.head(20))\n",
    "\n",
    "probs_29_49['marginal_prob'] = np.where(probs_29_49['dtc'] == 0, probs_29_49['avg_cumhaz'], probs_29_49['avg_cumhaz'] - probs_29_49['lag'])\n",
    "#print(probs_29_49.head(60))\n",
    "\n",
    "lead_probs_28day = lead_probs_28day[(lead_probs_28day['dtc'] <= 28)]\n",
    "lead_probs_28day = lead_probs_28day.sort_values(by = ['date_lead', 'dtc'])\n",
    "lead_probs_28day['lag'] = lead_probs_28day.groupby(['date_lead'])['avg_cumhaz'].shift(1)\n",
    "print(lead_probs_28day.head(40))\n",
    "\n",
    "lead_probs_28day['marginal_prob'] = np.where(lead_probs_28day['dtc'] == 0, lead_probs_28day['avg_cumhaz'], lead_probs_28day['avg_cumhaz'] - lead_probs_28day['lag'])\n",
    "#print(lead_probs_28day.head(60))\n",
    "\n",
    "#Restricting the probabilities to only 29 to 49 probabilities only\n",
    "probs_29_49 = probs_29_49[(probs_29_49['dtc'] <= 49) & (probs_29_49['dtc'] >= 29)]\n",
    "#print(probs_29_49.groupby(['date_lead']).size())\n",
    "\n",
    "#Appending the 28 day forecast with 29 forecast\n",
    "final_probs = lead_probs_28day.append(probs_29_49, ignore_index = True)\n",
    "final_probs = final_probs.drop(['key'], axis = 1)\n",
    "final_probs.sort_values(by = ['date_lead', 'dtc'])\n",
    "print(\"Frequency by Date\",final_probs.groupby(['date_lead']).size())\n",
    "print(final_probs.head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_cumhaz</th>\n",
       "      <th>avg_survival</th>\n",
       "      <th>date_lead</th>\n",
       "      <th>dtc</th>\n",
       "      <th>lag</th>\n",
       "      <th>marginal_prob</th>\n",
       "      <th>lead_gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.982498</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025331</td>\n",
       "      <td>0.975056</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034114</td>\n",
       "      <td>0.966577</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.955719</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034114</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058490</td>\n",
       "      <td>0.943469</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.070819</td>\n",
       "      <td>0.932021</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058490</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086110</td>\n",
       "      <td>0.918038</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.070819</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.105091</td>\n",
       "      <td>0.901003</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>7</td>\n",
       "      <td>0.086110</td>\n",
       "      <td>0.018981</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.123446</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.105091</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.141874</td>\n",
       "      <td>0.868956</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>9</td>\n",
       "      <td>0.123446</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob  lead_gen\n",
       "0    0.017695      0.982498 2018-02-01    0       NaN       0.017695      1676\n",
       "1    0.025331      0.975056 2018-02-01    1  0.017695       0.007635      1676\n",
       "2    0.034114      0.966577 2018-02-01    2  0.025331       0.008783      1676\n",
       "3    0.045488      0.955719 2018-02-01    3  0.034114       0.011375      1676\n",
       "4    0.058490      0.943469 2018-02-01    4  0.045488       0.013002      1676\n",
       "5    0.070819      0.932021 2018-02-01    5  0.058490       0.012329      1676\n",
       "6    0.086110      0.918038 2018-02-01    6  0.070819       0.015291      1676\n",
       "7    0.105091      0.901003 2018-02-01    7  0.086110       0.018981      1676\n",
       "8    0.123446      0.884848 2018-02-01    8  0.105091       0.018355      1676\n",
       "9    0.141874      0.868956 2018-02-01    9  0.123446       0.018428      1676"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging with number of leads\n",
    "final_probs = final_probs.merge(leads_number, how = 'left', on = 'date_lead')\n",
    "final_probs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_cumhaz                   float64\n",
      "avg_survival                 float64\n",
      "date_lead             datetime64[ns]\n",
      "dtc                            int64\n",
      "lag                          float64\n",
      "marginal_prob                float64\n",
      "lead_gen                       int64\n",
      "date_sold             datetime64[ns]\n",
      "converts                     float64\n",
      "predicted_converts           float64\n",
      "dtc_weekday                   object\n",
      "weekday_coeff                float64\n",
      "pred_errors                  float64\n",
      "new_pred_converts            float64\n",
      "dtype: object\n",
      "\n",
      "dtc           int64\n",
      "converts    float64\n",
      "dtype: object\n",
      "   dtc  converts\n",
      "0    0    4529.0\n",
      "1    1    1788.0\n",
      "2    2    2112.0\n",
      "3    3    2585.0\n",
      "4    4    2784.0\n",
      "5    5    2688.0\n",
      "6    6    3227.0\n",
      "7    7    3813.0\n",
      "8    8    3570.0\n",
      "9    9    3341.0\n",
      "2018-08-31 00:00:00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date_lead'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date_lead'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-2b26d4520681>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date_lead'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mfinal_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'date_lead'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'date_sold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m   4720\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4721\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4722\u001b[1;33m                      copy=copy, indicator=indicator)\n\u001b[0m\u001b[0;32m   4723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4724\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m     51\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                          copy=copy, indicator=indicator)\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m    556\u001b[0m         (self.left_join_keys,\n\u001b[0;32m    557\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    808\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date_lead'"
     ]
    }
   ],
   "source": [
    "#Matching with actuals\n",
    "\n",
    "#Create date_sold\n",
    "final_probs['date_sold'] = final_probs['date_lead']\n",
    "final_probs['date_sold'] += pd.to_timedelta(final_probs['dtc'], unit = 'D')\n",
    "final_probs.head(10)\n",
    "\n",
    "print(final_probs.dtypes)\n",
    "print(\"\")\n",
    "print(actuals.dtypes)\n",
    "print(actuals.head(10))\n",
    "\n",
    "print(max(final_probs['date_lead']))\n",
    "\n",
    "final_probs = final_probs.merge(actuals, how = 'left', on = ['date_lead', 'date_sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob  \\\n",
      "0    0.017695      0.982498 2018-02-01    0       NaN       0.017695   \n",
      "1    0.025331      0.975056 2018-02-01    1  0.017695       0.007635   \n",
      "2    0.034114      0.966577 2018-02-01    2  0.025331       0.008783   \n",
      "3    0.045488      0.955719 2018-02-01    3  0.034114       0.011375   \n",
      "4    0.058490      0.943469 2018-02-01    4  0.045488       0.013002   \n",
      "5    0.070819      0.932021 2018-02-01    5  0.058490       0.012329   \n",
      "6    0.086110      0.918038 2018-02-01    6  0.070819       0.015291   \n",
      "7    0.105091      0.901003 2018-02-01    7  0.086110       0.018981   \n",
      "8    0.123446      0.884848 2018-02-01    8  0.105091       0.018355   \n",
      "9    0.141874      0.868956 2018-02-01    9  0.123446       0.018428   \n",
      "\n",
      "   lead_gen  date_sold  converts  predicted_converts  \n",
      "0      1676 2018-02-01      39.0           29.138104  \n",
      "1      1676 2018-02-02      23.0           12.477572  \n",
      "2      1676 2018-02-03      10.0           14.228634  \n",
      "3      1676 2018-02-04       NaN           18.219525  \n",
      "4      1676 2018-02-05      19.0           20.559528  \n",
      "5      1676 2018-02-06      19.0           19.258038  \n",
      "6      1676 2018-02-07      24.0           23.526824  \n",
      "7      1676 2018-02-08      26.0           28.662813  \n",
      "8      1676 2018-02-09      39.0           27.220812  \n",
      "9      1676 2018-02-10       6.0           26.838543  \n"
     ]
    }
   ],
   "source": [
    "#Predicted probability\n",
    "final_probs['predicted_converts'] = final_probs['avg_survival'] * final_probs['marginal_prob'] * final_probs['lead_gen']\n",
    "print(final_probs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob  \\\n",
      "0    0.017695      0.982498 2018-02-01    0       NaN       0.017695   \n",
      "1    0.025331      0.975056 2018-02-01    1  0.017695       0.007635   \n",
      "2    0.034114      0.966577 2018-02-01    2  0.025331       0.008783   \n",
      "3    0.045488      0.955719 2018-02-01    3  0.034114       0.011375   \n",
      "4    0.058490      0.943469 2018-02-01    4  0.045488       0.013002   \n",
      "5    0.070819      0.932021 2018-02-01    5  0.058490       0.012329   \n",
      "6    0.086110      0.918038 2018-02-01    6  0.070819       0.015291   \n",
      "7    0.105091      0.901003 2018-02-01    7  0.086110       0.018981   \n",
      "8    0.123446      0.884848 2018-02-01    8  0.105091       0.018355   \n",
      "9    0.141874      0.868956 2018-02-01    9  0.123446       0.018428   \n",
      "\n",
      "   lead_gen  date_sold  converts  predicted_converts dtc_weekday  \n",
      "0      1676 2018-02-01      39.0           29.138104    Thursday  \n",
      "1      1676 2018-02-02      23.0           12.477572      Friday  \n",
      "2      1676 2018-02-03      10.0           14.228634    Saturday  \n",
      "3      1676 2018-02-04       NaN           18.219525      Sunday  \n",
      "4      1676 2018-02-05      19.0           20.559528      Monday  \n",
      "5      1676 2018-02-06      19.0           19.258038     Tuesday  \n",
      "6      1676 2018-02-07      24.0           23.526824   Wednesday  \n",
      "7      1676 2018-02-08      26.0           28.662813    Thursday  \n",
      "8      1676 2018-02-09      39.0           27.220812      Friday  \n",
      "9      1676 2018-02-10       6.0           26.838543    Saturday  \n"
     ]
    }
   ],
   "source": [
    "#Creating weekdays\n",
    "final_probs['dtc_weekday'] = final_probs['date_sold'].dt.weekday_name\n",
    "print(final_probs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_cumhaz  avg_survival  date_lead  dtc       lag  marginal_prob  \\\n",
      "0    0.017695      0.982498 2018-02-01    0       NaN       0.017695   \n",
      "1    0.025331      0.975056 2018-02-01    1  0.017695       0.007635   \n",
      "2    0.034114      0.966577 2018-02-01    2  0.025331       0.008783   \n",
      "3    0.045488      0.955719 2018-02-01    3  0.034114       0.011375   \n",
      "4    0.058490      0.943469 2018-02-01    4  0.045488       0.013002   \n",
      "5    0.070819      0.932021 2018-02-01    5  0.058490       0.012329   \n",
      "6    0.086110      0.918038 2018-02-01    6  0.070819       0.015291   \n",
      "7    0.105091      0.901003 2018-02-01    7  0.086110       0.018981   \n",
      "8    0.123446      0.884848 2018-02-01    8  0.105091       0.018355   \n",
      "9    0.141874      0.868956 2018-02-01    9  0.123446       0.018428   \n",
      "\n",
      "   lead_gen  date_sold  converts  predicted_converts dtc_weekday  \\\n",
      "0      1676 2018-02-01      39.0           29.138104    Thursday   \n",
      "1      1676 2018-02-02      23.0           12.477572      Friday   \n",
      "2      1676 2018-02-03      10.0           14.228634    Saturday   \n",
      "3      1676 2018-02-04       NaN           18.219525      Sunday   \n",
      "4      1676 2018-02-05      19.0           20.559528      Monday   \n",
      "5      1676 2018-02-06      19.0           19.258038     Tuesday   \n",
      "6      1676 2018-02-07      24.0           23.526824   Wednesday   \n",
      "7      1676 2018-02-08      26.0           28.662813    Thursday   \n",
      "8      1676 2018-02-09      39.0           27.220812      Friday   \n",
      "9      1676 2018-02-10       6.0           26.838543    Saturday   \n",
      "\n",
      "   weekday_coeff  pred_errors  new_pred_converts  month  \n",
      "0        -0.3215      -0.0217          28.505807      2  \n",
      "1         0.0000       0.2831          16.009973      2  \n",
      "2        -0.6210      -0.3546           9.183161      2  \n",
      "3        -0.9312      -0.6815           5.802919      2  \n",
      "4        -0.3706      -0.1376          17.730537      2  \n",
      "5        -0.4055      -0.1892          15.614418      2  \n",
      "6        -0.4981      -0.2985          16.504067      2  \n",
      "7        -0.3215      -0.1386          24.690147      2  \n",
      "8         0.0000       0.1662          31.744911      2  \n",
      "9        -0.6210      -0.4715          14.184170      2  \n",
      "date_sold\n",
      "2018-02-01     39.0\n",
      "2018-02-02     72.0\n",
      "2018-02-03     28.0\n",
      "2018-02-04     11.0\n",
      "2018-02-05     67.0\n",
      "2018-02-06     85.0\n",
      "2018-02-07    105.0\n",
      "2018-02-08    159.0\n",
      "2018-02-09    266.0\n",
      "2018-02-10     70.0\n",
      "2018-02-11      9.0\n",
      "2018-02-12    149.0\n",
      "2018-02-13    215.0\n",
      "2018-02-14    195.0\n",
      "2018-02-15    264.0\n",
      "2018-02-16    365.0\n",
      "2018-02-17    153.0\n",
      "2018-02-18     14.0\n",
      "2018-02-19    222.0\n",
      "2018-02-20    341.0\n",
      "2018-02-21    332.0\n",
      "2018-02-22    500.0\n",
      "2018-02-23    940.0\n",
      "2018-02-24    257.0\n",
      "2018-02-25     50.0\n",
      "2018-02-26    394.0\n",
      "2018-02-27    375.0\n",
      "2018-02-28    408.0\n",
      "2018-03-01    381.0\n",
      "2018-03-02    903.0\n",
      "              ...  \n",
      "2018-06-02    407.0\n",
      "2018-06-03     59.0\n",
      "2018-06-04    585.0\n",
      "2018-06-05    741.0\n",
      "2018-06-06    672.0\n",
      "2018-06-07    756.0\n",
      "2018-06-08    959.0\n",
      "2018-06-09    367.0\n",
      "2018-06-10     77.0\n",
      "2018-06-11    482.0\n",
      "2018-06-12    473.0\n",
      "2018-06-13    380.0\n",
      "2018-06-14    442.0\n",
      "2018-06-15    594.0\n",
      "2018-06-16    254.0\n",
      "2018-06-17     19.0\n",
      "2018-06-18    297.0\n",
      "2018-06-19    333.0\n",
      "2018-06-20    252.0\n",
      "2018-06-21    219.0\n",
      "2018-06-22    342.0\n",
      "2018-06-23     89.0\n",
      "2018-06-24     11.0\n",
      "2018-06-25    212.0\n",
      "2018-06-26    136.0\n",
      "2018-06-27    152.0\n",
      "2018-06-28    149.0\n",
      "2018-06-29    178.0\n",
      "2018-06-30     59.0\n",
      "2018-07-01      8.0\n",
      "Name: converts, Length: 151, dtype: float64\n",
      "   dtc  new_pred_converts\n",
      "0    0        4696.866622\n",
      "1    1        1881.112080\n",
      "2    2        2110.662603\n",
      "3    3        2683.744582\n",
      "4    4        2942.627839\n",
      "5    5        2587.544295\n",
      "6    6        3213.462177\n",
      "7    7        3960.419300\n",
      "8    8        3537.880179\n",
      "9    9        3422.794764\n",
      "\n",
      "   dtc  converts\n",
      "0    0    4529.0\n",
      "1    1    1788.0\n",
      "2    2    2112.0\n",
      "3    3    2585.0\n",
      "4    4    2784.0\n",
      "5    5    2688.0\n",
      "6    6    3227.0\n",
      "7    7    3813.0\n",
      "8    8    3570.0\n",
      "9    9    3341.0\n",
      "    dtc  new_pred_converts  converts    errors\n",
      "0     0        4696.866622    4529.0  0.037065\n",
      "1     1        1881.112080    1788.0  0.052076\n",
      "2     2        2110.662603    2112.0  0.000633\n",
      "3     3        2683.744582    2585.0  0.038199\n",
      "4     4        2942.627839    2784.0  0.056978\n",
      "5     5        2587.544295    2688.0  0.037372\n",
      "6     6        3213.462177    3227.0  0.004195\n",
      "7     7        3960.419300    3813.0  0.038662\n",
      "8     8        3537.880179    3570.0  0.008997\n",
      "9     9        3422.794764    3341.0  0.024482\n",
      "10   10        3494.754397    3332.0  0.048846\n",
      "11   11        3362.505121    3140.0  0.070862\n",
      "12   12        2731.981584    2843.0  0.039050\n",
      "13   13        3092.732233    3020.0  0.024084\n",
      "14   14        3308.692216    3004.0  0.101429\n",
      "15   15        2724.237422    2697.0  0.010099\n",
      "16   16        2552.857451    2504.0  0.019512\n",
      "17   17        2511.861026    2357.0  0.065703\n",
      "18   18        2288.400813    2197.0  0.041603\n",
      "19   19        1799.856634    1870.0  0.037510\n",
      "20   20        2041.241010    1893.0  0.078310\n",
      "21   21        2079.416232    1787.0  0.163635\n",
      "22   22        1690.960950    1599.0  0.057512\n",
      "23   23        1598.496694    1531.0  0.044087\n",
      "24   24        1584.298134    1426.0  0.111009\n",
      "25   25        1436.644314    1250.0  0.149315\n",
      "26   26        1109.613137    1117.0  0.006613\n",
      "27   27        1183.988241    1117.0  0.059972\n",
      "28   28        1244.648245    1075.0  0.157812\n",
      "29   29         920.292561     979.0  0.059967\n",
      "30   30         837.969656     881.0  0.048843\n",
      "31   31         794.430437     818.0  0.028814\n",
      "32   32         737.559173     734.0  0.004849\n",
      "33   33         538.733055     741.0  0.272965\n",
      "34   34         593.933538     635.0  0.064672\n",
      "35   35         624.249703     640.0  0.024610\n",
      "36   36         452.000368     572.0  0.209790\n",
      "37   37         422.779140     523.0  0.191627\n",
      "38   38         400.734998     472.0  0.150985\n",
      "39   39         350.793948     455.0  0.229024\n",
      "40   40         241.812420     378.0  0.360285\n",
      "41   41         267.818868     393.0  0.318527\n",
      "42   42         275.053962     396.0  0.305419\n",
      "43   43         177.789250     328.0  0.457960\n",
      "44   44         163.157238     278.0  0.413103\n",
      "45   45         145.150839     289.0  0.497748\n",
      "46   46         117.195148     242.0  0.515723\n",
      "47   47          46.854051     254.0  0.815535\n",
      "48   48          41.419276     244.0  0.830249\n",
      "49   49          68.197963     192.0  0.644802\n"
     ]
    }
   ],
   "source": [
    "final_scores = final_probs\n",
    "final_scores['weekday_coeff'] = np.where(final_scores['dtc_weekday'] == 'Monday', -0.3706,\n",
    "                                        np.where(final_scores['dtc_weekday'] == 'Tuesday', -0.4055,\n",
    "                                                np.where(final_scores['dtc_weekday'] == 'Wednesday', -0.4981,\n",
    "                                                         np.where(final_scores['dtc_weekday'] == 'Thursday', -0.3215,\n",
    "                                                                  np.where(final_scores['dtc_weekday'] == 'Saturday', -0.6210,\n",
    "                                                                           np.where(final_scores['dtc_weekday'] == 'Sunday', -0.9312,0\n",
    "                                                                                   ))))))\n",
    "\n",
    "final_scores['pred_errors'] = 0.2998 + final_scores['weekday_coeff'] + (-0.0167 * final_scores['dtc'])\n",
    "final_scores['new_pred_converts'] = (1+final_scores['pred_errors']) * final_probs['predicted_converts']\n",
    "final_scores = final_scores[(final_scores['date_sold'] <= '2018-07-01') & (final_scores['date_lead'] <= '2018-05-31')]\n",
    "final_scores['month'] = final_scores['date_lead'].dt.month\n",
    "print(final_scores.head(10))\n",
    "\n",
    "print(final_scores.groupby(['date_sold'])['converts'].sum())\n",
    "\n",
    "predicts = pd.DataFrame(final_scores.groupby(['dtc'])['new_pred_converts'].sum()).reset_index()\n",
    "actuals = pd.DataFrame(final_scores.groupby(['dtc'])['converts'].sum()).reset_index()\n",
    "print(predicts.head(10))\n",
    "print(\"\")\n",
    "print(actuals.head(10))\n",
    "final = predicts.merge(actuals, how = 'left', on = ['dtc'])\n",
    "final['errors'] = abs(final['new_pred_converts'] - final['converts'])/final['converts']\n",
    "print(final)\n",
    "\n",
    "final.to_excel(\"C:\\\\Users\\\\skbandha\\\\OneDrive - Lowe's Companies Inc\\\\Projects\\\\PSE Leads\\\\Final_Errors.xlsx\", sheet_name='sheet1', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
